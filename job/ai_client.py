#!/usr/bin/env python
# -*- coding:utf-8 -*-
"""
ai_client.py
ç»Ÿä¸€çœŸå® AI è°ƒç”¨å®¢æˆ·ç«¯
å§‹ç»ˆå°è¯•è°ƒç”¨è¿œç«¯æ¨¡å‹æ¥å£ï¼›è‹¥ç¼ºå°‘ token è¿”å›é”™è¯¯ä¿¡æ¯ã€‚
"""
import os, time, json, math
from typing import Dict, Any, Optional
from datetime import datetime, timedelta
import pandas as pd
import requests

class AIClient:
    def __init__(self, api_url: Optional[str] = None, api_token: Optional[str] = None,
                 model: Optional[str] = None, timeout: float = 60.0, retries: int = 1):
        """æ„é€ å‡½æ•°
        Args:
            api_url: è¦†ç›–é»˜è®¤æ¥å£åœ°å€ï¼Œé»˜è®¤ä»ç¯å¢ƒå˜é‡ SILICONFLOW_API_URL æˆ–å¸¸ç”¨åœ°å€ã€‚
            api_token: APIè®¿é—®å¯†é’¥ï¼ˆå»ºè®®é€šè¿‡ç¯å¢ƒå˜é‡ SILICONFLOW_API_TOKENï¼‰ã€‚
            model: ä½¿ç”¨çš„æ¨¡å‹åç§°ï¼ˆä¾‹å¦‚ deepseek-ai/DeepSeek-V3ï¼‰ï¼Œå¯é€šè¿‡ SILICONFLOW_MODEL è¦†ç›–ã€‚
            timeout: å•æ¬¡HTTPè¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ã€‚
            retries: å¤±è´¥åé‡è¯•æ¬¡æ•°ï¼ˆä¸å«é¦–æ¬¡ï¼‰ã€‚
        å®‰å…¨è¯´æ˜ï¼šçœŸå® token ä¸åº”å†™å…¥ä»£ç ï¼Œè¿™é‡Œé»˜è®¤è¯»å–ç¯å¢ƒå˜é‡ï¼›è‹¥æœªæä¾›çœŸå® token å°†åœ¨è°ƒç”¨æ—¶ç»™å‡ºé”™è¯¯æç¤ºã€‚
        """
        # çœŸå®è°ƒç”¨æ‰€éœ€é…ç½®
        self.api_url = api_url or os.getenv('SILICONFLOW_API_URL', 'https://api.siliconflow.cn/v1/chat/completions')
        self.api_token = api_token or os.getenv('SILICONFLOW_API_TOKEN', 'sk-nypfpxrbfrlrtxbzczpkrgexpxjnaitxbubuojjhtcxgedjm')
        self.model = model or os.getenv('SILICONFLOW_MODEL', 'deepseek-ai/DeepSeek-V3')
        self.timeout = timeout
        self.retries = max(0, retries)
        print(f"âœ… AIClient åˆå§‹åŒ–: model={self.model}, retries={self.retries}")

    def call(self, report: Dict[str, Any], hist_df: Optional[pd.DataFrame] = None, months: int = 6,
             use_toon: bool = True, use_ai: bool = True,
             temperature: float = 0.7, max_tokens: int = 1024) -> Dict[str, Any]:
        """ç»Ÿä¸€è°ƒç”¨å…¥å£ï¼ˆå§‹ç»ˆçœŸå®æ¥å£è°ƒç”¨ï¼Œè‹¥ç¼ºå°‘ token è¿”å›é”™è¯¯ï¼‰
        æµç¨‹ï¼š
          1. æ ¹æ®ç»“æ„åŒ–æŠ¥å‘Šç”Ÿæˆäººç±»å¯è¯»æç¤ºè¯ human_promptã€‚
          2. å¯é€‰ï¼šå‹ç¼©è¿‘ months æœˆå†å²æ”¶ç›˜ä»·ç”Ÿæˆ Toon æ ¼å¼ï¼ˆå« SEQ åºåˆ—ï¼‰ã€‚
          3. ç”Ÿæˆæœ€ç»ˆ prompt å¹¶è°ƒç”¨è¿œç«¯æ¨¡å‹æ¥å£ã€‚
        Args:
            report: ç”± ReportGenerator ç”Ÿæˆçš„ç»“æ„åŒ–æŠ¥å‘Šå­—å…¸ã€‚
            hist_df: å†å²ä»·æ ¼ DataFrameï¼Œç”¨äºç”Ÿæˆå‹ç¼©åºåˆ—ï¼ˆå¯é€‰ï¼‰ã€‚
            months: å‹ç¼©å†å²çš„æœˆä»½åŒºé—´ï¼ˆé»˜è®¤6ï¼‰ã€‚
            use_toon: True ä½¿ç”¨ç´§å‡‘ Toon æ ¼å¼ï¼›False ä½¿ç”¨äººç±»å¯è¯»æ ¼å¼ã€‚
            use_ai: True æ‰§è¡ŒçœŸå®æ¨¡å‹è°ƒç”¨ï¼›False ä»…è¿”å›æ„é€ çš„ promptã€‚
            temperature: é‡‡æ ·æ¸©åº¦ï¼ˆæ§åˆ¶éšæœºæ€§ï¼‰ã€‚
            max_tokens: æœ€å¤§ç”Ÿæˆ token æ•°ã€‚
        Returns:
            dictï¼šåŒ…å« prompt / ai_summary / has_history / errorï¼ˆè‹¥å¤±è´¥ï¼‰ç­‰ã€‚
        """
        # æ„é€ æç¤ºè¯
        hist_info = self._compress_history(hist_df, months=months) if (use_toon and hist_df is not None) else None
        prompt = self._build_toon_prompt(report, hist_info)
        system_prompt = self._build_system_prompt()
        result: Dict[str, Any] = {
            'prompt': prompt,
            'has_history': hist_info is not None,
            'model': self.model,
            'system_prompt': system_prompt
        }
        print("="*80)
        print(f"ğŸš€ è°ƒç”¨ AI æ¨¡å‹: {result}")
        # ç¼ºå°‘ token æ—¶ç›´æ¥è¿”å›é”™è¯¯
        if not self.api_token:
            result['error'] = 'ç¼ºå°‘ API Token (SILICONFLOW_API_TOKEN)'
            return result
        payload = self._build_payload(system_prompt, prompt, temperature, max_tokens)
        if use_ai:
            api_response = self._request_api(payload)
            result.update(api_response)
        return result

    def _build_payload(self, system_prompt: str, user_prompt: str, temperature: float, max_tokens: int) -> Dict[str, Any]:
        """æ„å»ºç¡…åŸºæµåŠ¨å…¼å®¹çš„è¯·æ±‚ä½“
        Args:
            system_prompt: ç³»ç»Ÿçº§è§’è‰²æç¤º
            user_prompt: ç”¨æˆ·ä¸»ä½“å†…å®¹ï¼ˆToon æˆ–äººç±»å¯è¯»ï¼‰
            temperature: éšæœºæ€§å‚æ•°
            max_tokens: æœ€å¤§ç”Ÿæˆ token é™åˆ¶
        Returns:
            dict: å¯ç›´æ¥åºåˆ—åŒ–ä¸º JSON çš„è¯·æ±‚ä½“ã€‚
        """
        return {
            'model': self.model,
            'messages': [
                {'role': 'system', 'content': system_prompt},
                {'role': 'user', 'content': user_prompt}
            ],
            'temperature': temperature,
            'max_tokens': max_tokens
        }

    def _request_api(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡ŒçœŸå® HTTP è¯·æ±‚è°ƒç”¨æ¨¡å‹æœåŠ¡
        å…·å¤‡ï¼š
          - é‡è¯•æœºåˆ¶ï¼ˆçº¿æ€§é€€é¿ï¼‰
          - è¶…æ—¶ä¸å¼‚å¸¸æ•è·
        Args:
            payload: å·²æ„å»ºçš„è¯·æ±‚ä½“
        Returns:
            dict: åŒ…å« ai_summary æˆ– error / details
        """
        headers = {
            'Authorization': f'Bearer {self.api_token}',
            'Content-Type': 'application/json'
        }
        last_error = None
        for attempt in range(self.retries + 1):
            try:
                start = time.time()
                resp = requests.post(self.api_url, headers=headers, json=payload, timeout=self.timeout)
                elapsed = round(time.time() - start, 3)
                if resp.status_code >= 400:
                    return {'error': f'HTTP {resp.status_code}', 'details': resp.text[:500], 'latency': elapsed}
                data = resp.json()
                text = self._extract_text(data)
                return {'ai_summary': text, 'raw_response': data, 'latency': elapsed}
            except requests.exceptions.Timeout as e:
                last_error = f'Timeout: {e}'
            except requests.exceptions.RequestException as e:
                last_error = f'RequestException: {e}'
            except json.JSONDecodeError as e:
                last_error = f'JSONDecodeError: {e}'
            time.sleep(1.0 * (attempt + 1))
        return {'error': 'APIè°ƒç”¨å¤±è´¥', 'details': last_error, 'latency': None}

    def _extract_text(self, response: Dict[str, Any]) -> str:
        """ä»æ¨¡å‹è¿”å›ç»“æ„ä¸­æå–æ–‡æœ¬
        å…¼å®¹ OpenAI é£æ ¼ï¼šresponse['choices'][0]['message']['content']
        è‹¥ç»“æ„å¼‚å¸¸æˆ–æ— å†…å®¹ï¼Œåˆ™è¿”å›éƒ¨åˆ†åŸå§‹ JSON æˆ–é”™è¯¯ä¿¡æ¯ã€‚
        Args:
            response: å®Œæ•´çš„æ¥å£è¿”å›å­—å…¸
        Returns:
            str: æå–å‡ºçš„æ–‡æœ¬å†…å®¹æˆ–å ä½è¯´æ˜
        """
        try:
            choices = response.get('choices') or []
            if not choices:
                return '[æ— choicesè¿”å›]'
            msg = choices[0].get('message') or {}
            content = msg.get('content')
            return content.strip() if content else json.dumps(response)[:500]
        except Exception as e:
            return f'[è§£æå¤±è´¥] {e}'

    # å†å²åºåˆ—å‹ç¼© -------------------------------------------------
    def _compress_history(self, hist_df: Optional[pd.DataFrame], months: int = 6, col: str = 'æ”¶ç›˜', max_points: int = 120) -> Optional[Dict[str, Any]]:
        """å‹ç¼©è¿‘ months æœˆçš„æ”¶ç›˜ä»·åºåˆ—ä¸ºç´§å‡‘æ•´æ•°åºåˆ—
        æ­¥éª¤ï¼š
          1. æŒ‰æœˆä»½è¿‡æ»¤æœ€è¿‘ N å¤©æ•°æ®
          2. ä¸‹é‡‡æ ·è‡³ä¸è¶…è¿‡ max_points ä¸ªç‚¹
          3. ç”¨é¦–å€¼å½’ä¸€åŒ– (value/base*1000) å¹¶å››èˆäº”å…¥ä¸ºæ•´æ•°ï¼Œä¾¿äºå‡å°‘ token
          4. è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡ï¼šæœ€å° / æœ€å¤§ / å‡å€¼ / æ ‡å‡†å·® / æ€»æ¶¨å¹… / å¹´åŒ–æ³¢åŠ¨è¿‘ä¼¼
        Args:
            hist_df: å†å²æ•°æ® DataFrameï¼ˆç´¢å¼•ä¸ºæ—¥æœŸï¼‰
            months: å‘åè¿½æº¯çš„æœˆä»½æ•°
            col: ä½¿ç”¨çš„åˆ—åï¼ˆé»˜è®¤ 'æ”¶ç›˜'ï¼‰
            max_points: æœ€å¤§ä¿ç•™ç‚¹æ•°
        Returns:
            dict æˆ– Noneï¼šåŒ…å«å‹ç¼©ä¿¡æ¯å’Œç»Ÿè®¡ï¼›æ— æ•°æ®æ—¶è¿”å› None
        """
        if hist_df is None or hist_df.empty or col not in hist_df.columns:
            return None
        if not isinstance(hist_df.index, pd.DatetimeIndex):
            try: hist_df.index = pd.to_datetime(hist_df.index)
            except Exception: pass
        cutoff = datetime.now() - timedelta(days=months*30)
        df = hist_df[hist_df.index >= cutoff]
        if df.empty: return None
        series = df[col].dropna(); values = series.tolist(); n = len(values)
        stride = math.ceil(n / max_points) if n > max_points else 1
        sampled = values[::stride]; base = sampled[0]
        if base == 0: base = next((v for v in sampled if v != 0), 1.0)
        norm_seq = [int(round(v / base * 1000)) for v in sampled]
        stats_min, stats_max = min(values), max(values)
        stats_mean = sum(values)/n
        stats_std = (sum((v-stats_mean)**2 for v in values)/(n-1))**0.5 if n>1 else 0.0
        stats_ret = (values[-1]/values[0]-1.0) if values[0]!=0 else 0.0
        annual_factor = 365/(months*30) if months>0 else 1
        stats_vol = stats_std/stats_mean*math.sqrt(annual_factor) if stats_mean!=0 else 0.0
        return {'seq':','.join(map(str,norm_seq)),'base':round(base,4),'len':n,'stride':stride,'points':len(norm_seq),
                'min':round(stats_min,4),'max':round(stats_max,4),'ret':round(stats_ret,4),'std':round(stats_std,4),'vol':round(stats_vol,4)}

    # Toon å‹ç¼©æç¤ºè¯ -------------------------------------------------
    def _build_toon_prompt(self, report: Dict[str, Any], hist_info: Optional[Dict[str, Any]] = None) -> str:
        """ç”Ÿæˆ Toon ç´§å‡‘æ ¼å¼æç¤ºè¯
        ç»“æ„ï¼š
            M: åŸºæœ¬ä¿¡æ¯ (ä»£ç /åç§°)
            P: ä»·æ ¼ä¿¡æ¯ (æ—¥æœŸ/å¼€é«˜ä½æ”¶/æˆäº¤é‡)
            S: æŠ€æœ¯ä¿¡å· (kdj, macd, rsi => 1/0)
            SUM: æ±‡æ€» (ä¿¡å·æ•°/æ¿€æ´»åˆ—è¡¨/å‹ç¼©å»ºè®®)
            TS: å†å²ç»Ÿè®¡ (len/pts/stride/base/ret/min/max/std/vol)
            SEQ: å‹ç¼©å†å²åºåˆ— (æ•´æ•°åˆ—è¡¨å­—ç¬¦ä¸²)
        Args:
            report: ç»“æ„åŒ–æŠ¥å‘Š
            hist_info: ç”± _compress_history è¿”å›çš„å†å²å‹ç¼©ä¿¡æ¯
        Returns:
            str: Toon æ ¼å¼å•è¡Œå­—ç¬¦ä¸²
        """
        meta = report.get('meta', {}); price = report.get('price', {}); signals = report.get('signals', {}); summary = report.get('summary', {})
        kdj = 1 if signals.get('kdj_golden_cross') else 0
        macd = 1 if signals.get('macd_golden_cross') else 0
        rsi = 1 if signals.get('rsi_oversold') else 0
        acts = summary.get('active_signals', []); act_str = '|'.join(acts) if acts else ''
        suggestion = summary.get('suggestion', '')
        for k,v in {'åŒé‡‘å‰':'DXC','çªç ´':'TP','å°‘é‡è¯•æ¢':'SLST','ç»§ç»­è§‚å¯Ÿ':'GJGC','å…±æŒ¯':'GZ'}.items(): suggestion = suggestion.replace(k,v)
        suggestion = suggestion.strip()
        toon = (f"M:c={meta.get('stock_code','')},n={meta.get('stock_name','')}"
                f";P:d={price.get('date','')},o={price.get('open',0):.2f},h={price.get('high',0):.2f},l={price.get('low',0):.2f},c={price.get('close',0):.2f},v={int(price.get('volume',0))}"
                f";S:kdj={kdj},macd={macd},rsi={rsi}" 
                f";SUM:cnt={summary.get('signal_count',0)},act={act_str},sug={suggestion}")
        if hist_info:
            toon += (f";TS:len={hist_info['len']},pts={hist_info['points']},stride={hist_info['stride']},base={hist_info['base']},ret={hist_info['ret']},min={hist_info['min']},max={hist_info['max']},std={hist_info['std']},vol={hist_info['vol']}" 
                     f";SEQ:{hist_info['seq']}")
        return toon

    def _build_system_prompt(self):
        """ç”Ÿæˆç³»ç»Ÿæç¤ºè¯"""
        system_prompt = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è‚¡ç¥¨åˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿æ ¹æ®æŠ€æœ¯æŒ‡æ ‡å’Œå†å²æ•°æ®æä¾›ç®€æ´æœ‰åŠ›çš„äº¤æ˜“å»ºè®®ã€‚"
        return system_prompt

__all__ = ['AIClient']
