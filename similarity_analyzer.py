#!/usr/bin/env python
# -*- coding:utf-8 -*-
"""
Kçº¿å›¾èµ°åŠ¿ç›¸ä¼¼åº¦åˆ†æå™¨
åŸºäºå¤šç»´åº¦ç»¼åˆåˆ†æçš„è‚¡ç¥¨ä¸é‡‘ä»·èµ°åŠ¿ç›¸ä¼¼åº¦ç®—æ³•

ç®—æ³•è¯´æ˜ï¼š
1. ä»·æ ¼å˜åŒ–ç›¸å…³æ€§åˆ†æ - è®¡ç®—æ—¥æ¶¨è·Œå¹…çš„çš®å°”é€Šç›¸å…³ç³»æ•°
2. è¶‹åŠ¿æ–¹å‘ä¸€è‡´æ€§åˆ†æ - æ¯”è¾ƒç§»åŠ¨å¹³å‡çº¿çš„æ–œç‡æ–¹å‘
3. æ³¢åŠ¨æ€§ç›¸ä¼¼åº¦åˆ†æ - æ¯”è¾ƒä»·æ ¼æ³¢åŠ¨å¹…åº¦å’Œé¢‘ç‡
4. ä»·æ ¼æ¨¡å¼åŒ¹é…åˆ†æ - ä½¿ç”¨DTWç®—æ³•è®¡ç®—ä»·æ ¼åºåˆ—ç›¸ä¼¼åº¦
5. æˆäº¤é‡ä¸ä»·æ ¼å…³ç³»åˆ†æ - åˆ†ææˆäº¤é‡ä¸ä»·æ ¼å˜åŒ–çš„å…³ç³»ç›¸ä¼¼åº¦

æœ€ç»ˆè¾“å‡ºï¼š0-100çš„ç›¸ä¼¼åº¦åˆ†æ•°ï¼Œä»¥åŠè¯¦ç»†çš„å¯è§†åŒ–æ•°æ®
"""

import sys
import os
import numpy as np
import pandas as pd
from scipy import stats
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ akshareæºç ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.abspath('./akshare'))
import akshare as ak

# ä½¿ç”¨tslearnåº“è¿›è¡ŒDTWè®¡ç®— - ä¸“ä¸šçš„æ—¶é—´åºåˆ—åˆ†æåº“
from tslearn.metrics import dtw

class SimilarityAnalyzer:
    """
    Kçº¿å›¾èµ°åŠ¿ç›¸ä¼¼åº¦åˆ†æå™¨
    
    åŸºäºå¤šç»´åº¦ç»¼åˆåˆ†æï¼Œè®¡ç®—ä¸¤æ¡Kçº¿å›¾çš„èµ°åŠ¿ç›¸ä¼¼åº¦
    é€‚ç”¨äºè‚¡ç¥¨ä»·æ ¼ä¸é‡‘ä»·èµ°åŠ¿çš„å¯¹æ¯”åˆ†æ
    """
    
    def __init__(self):
        """
        åˆå§‹åŒ–ç›¸ä¼¼åº¦åˆ†æå™¨
        
        æƒé‡é…ç½®ï¼š
        - correlation: ä»·æ ¼å˜åŒ–ç›¸å…³æ€§ (30%)
        - trend: è¶‹åŠ¿æ–¹å‘ä¸€è‡´æ€§ (25%) 
        - volatility: æ³¢åŠ¨æ€§ç›¸ä¼¼åº¦ (20%)
        - pattern: ä»·æ ¼æ¨¡å¼åŒ¹é… (15%)
        - volume: æˆäº¤é‡å…³ç³» (10%)
        """
        self.weights = {
            'correlation': 0.30,      # ä»·æ ¼å˜åŒ–ç›¸å…³æ€§
            'trend': 0.25,            # è¶‹åŠ¿æ–¹å‘ä¸€è‡´æ€§  
            'volatility': 0.20,       # æ³¢åŠ¨æ€§ç›¸ä¼¼åº¦
            'pattern': 0.15,          # ä»·æ ¼æ¨¡å¼åŒ¹é…
            'volume': 0.10           # æˆäº¤é‡å…³ç³»
        }
        
        # æ•°æ®å­˜å‚¨
        self.stock_data = None
        self.gold_data = None
        
        print("Kçº¿å›¾èµ°åŠ¿ç›¸ä¼¼åº¦åˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"æƒé‡é…ç½®: {self.weights}")
    
    def prepare_data(self, months=6, stock_code='002155'):
        """
        å‡†å¤‡Kçº¿å›¾åˆ†ææ•°æ®
        
        åŠŸèƒ½ï¼š
        1. è·å–è‚¡ç¥¨å†å²æ•°æ®
        2. è·å–é‡‘ä»·å†å²æ•°æ®
        3. æ•°æ®æ¸…æ´—å’Œæ ¼å¼åŒ–
        4. æ•°æ®ç±»å‹è½¬æ¢
        
        Args:
            months (int): æ•°æ®æœˆæ•°
            stock_code (str): è‚¡ç¥¨ä»£ç 
            
        Returns:
            bool: æ•°æ®å‡†å¤‡æ˜¯å¦æˆåŠŸ
        """
        print(f"ğŸ”„ æ­£åœ¨å‡†å¤‡Kçº¿å›¾åˆ†ææ•°æ®...")
        
        try:
            # è·å–è‚¡ç¥¨æ•°æ®
            self.stock_data = self.get_stock_data(months, stock_code)
            
            if self.stock_data.empty:
                print(f"âŒ è‚¡ç¥¨{stock_code}æ•°æ®ä¸ºç©º")
                return False
                
        except Exception as e:
            print(f"âŒ å‡†å¤‡è‚¡ç¥¨{stock_code}æ•°æ®å¤±è´¥: {e}")
            return False
        
        # è‚¡ç¥¨æ•°æ®é¢„å¤„ç†
        print("ğŸ”§ æ­£åœ¨å¤„ç†è‚¡ç¥¨æ•°æ®...")
        self.stock_data['æ—¥æœŸ'] = pd.to_datetime(self.stock_data['æ—¥æœŸ'])
        self.stock_data = self.stock_data.set_index('æ—¥æœŸ')
        self.stock_data = self.stock_data.sort_index()
        
        # ç¡®ä¿OHLCæ•°æ®ä¸ºæ•°å€¼ç±»å‹
        numeric_columns = ['å¼€ç›˜', 'æœ€é«˜', 'æœ€ä½', 'æ”¶ç›˜', 'æˆäº¤é‡']
        for col in numeric_columns:
            if col in self.stock_data.columns:
                self.stock_data[col] = pd.to_numeric(self.stock_data[col], errors='coerce')
        
        # åˆ é™¤åŒ…å«NaNçš„è¡Œ
        self.stock_data = self.stock_data.dropna()
        
        print(f"âœ… è‚¡ç¥¨æ•°æ®å‡†å¤‡å®Œæˆï¼Œå½¢çŠ¶: {self.stock_data.shape}")
        print(f"ğŸ“Š è‚¡ç¥¨ä»·æ ¼èŒƒå›´: {self.stock_data['æ”¶ç›˜'].min():.2f} - {self.stock_data['æ”¶ç›˜'].max():.2f}")
        
        # è·å–ä¼¦æ•¦é‡‘æ•°æ®
        print(f"ğŸ¥‡ æ­£åœ¨å‡†å¤‡ä¼¦æ•¦é‡‘æ•°æ®...")
        self.gold_data = self.get_gold_data(months)
        
        if not self.gold_data.empty:
            # ä¼¦æ•¦é‡‘æ•°æ®é¢„å¤„ç†
            print("ğŸ”§ æ­£åœ¨å¤„ç†ä¼¦æ•¦é‡‘æ•°æ®...")
            
            # ç¡®ä¿OHLCæ•°æ®ä¸ºæ•°å€¼ç±»å‹
            numeric_columns = ['å¼€ç›˜', 'æœ€é«˜', 'æœ€ä½', 'æ”¶ç›˜', 'æˆäº¤é‡']
            for col in numeric_columns:
                if col in self.gold_data.columns:
                    self.gold_data[col] = pd.to_numeric(self.gold_data[col], errors='coerce')
            
            # åˆ é™¤åŒ…å«NaNçš„è¡Œ
            self.gold_data = self.gold_data.dropna()
            
            print(f"âœ… ä¼¦æ•¦é‡‘æ•°æ®å‡†å¤‡å®Œæˆï¼Œå½¢çŠ¶: {self.gold_data.shape}")
            print(f"ğŸ“Š ä¼¦æ•¦é‡‘ä»·æ ¼èŒƒå›´: ${self.gold_data['æ”¶ç›˜'].min():.2f} - ${self.gold_data['æ”¶ç›˜'].max():.2f}")
        else:
            print("âš ï¸ ä¼¦æ•¦é‡‘æ•°æ®ä¸ºç©ºï¼Œå°†ä½¿ç”¨ç©ºæ•°æ®")
        
        return True
    
    def get_stock_data(self, months=6, stock_code='002155'):
        """
        è·å–è‚¡ç¥¨å†å²æ•°æ®
        
        Args:
            months (int): è·å–æ•°æ®çš„æœˆæ•°ï¼Œé»˜è®¤6ä¸ªæœˆ
            stock_code (str): è‚¡ç¥¨ä»£ç ï¼Œé»˜è®¤002155ï¼ˆæ¹–å—é»„é‡‘ï¼‰
            
        Returns:
            pd.DataFrame: è‚¡ç¥¨å†å²æ•°æ®ï¼ŒåŒ…å«OHLCVæ•°æ®
        """
        print(f"ğŸ“Š æ­£åœ¨è·å–è‚¡ç¥¨{stock_code}è¿‘{months}ä¸ªæœˆçš„å†å²æ•°æ®...")
        
        # è®¡ç®—æ—¥æœŸèŒƒå›´
        end_date = datetime.now().strftime('%Y%m%d')
        start_date = (datetime.now() - timedelta(days=months*30)).strftime('%Y%m%d')
        
        try:
            # ä½¿ç”¨akshareè·å–è‚¡ç¥¨æ•°æ®
            stock_data = ak.stock_zh_a_hist(
                symbol=stock_code,
                period="daily",
                start_date=start_date,
                end_date=end_date,
                adjust="qfq"  # å‰å¤æƒ
            )
            
            if stock_data.empty:
                print(f"âŒ æœªè·å–åˆ°è‚¡ç¥¨{stock_code}çš„æ•°æ®")
                raise Exception(f"æ— æ³•è·å–è‚¡ç¥¨{stock_code}çš„å†å²æ•°æ®")
            
            # ç¡®ä¿ç´¢å¼•æ˜¯datetimeç±»å‹
            if not isinstance(stock_data.index, pd.DatetimeIndex):
                print(f"âš ï¸ è‚¡ç¥¨{stock_code}ç´¢å¼•ä¸æ˜¯DatetimeIndexï¼Œå°è¯•è½¬æ¢...")
                stock_data.index = pd.to_datetime(stock_data.index)
            
            print(f"âœ… æˆåŠŸè·å–è‚¡ç¥¨{stock_code}çš„ {len(stock_data)} æ¡æ•°æ®")
            print(f"ğŸ“ˆ æ•°æ®æ—¶é—´èŒƒå›´: {stock_data['æ—¥æœŸ'].min()} åˆ° {stock_data['æ—¥æœŸ'].max()}")
            return stock_data
            
        except Exception as e:
            print(f"âŒ è·å–è‚¡ç¥¨{stock_code}æ•°æ®å‡ºé”™: {e}")
            raise e
    
    def get_gold_data(self, months=6):
        """
        è·å–ä¼¦æ•¦é‡‘å†å²æ•°æ®
        
        Args:
            months (int): è·å–æ•°æ®çš„æœˆæ•°ï¼Œé»˜è®¤6ä¸ªæœˆ
            
        Returns:
            pd.DataFrame: ä¼¦æ•¦é‡‘å†å²æ•°æ®ï¼ŒåŒ…å«OHLCVæ ¼å¼
        """
        print(f"ğŸ¥‡ æ­£åœ¨è·å–ä¼¦æ•¦é‡‘è¿‘{months}ä¸ªæœˆçš„å†å²æ•°æ®...")
        
        try:
            # ä½¿ç”¨akshareè·å–ä¼¦æ•¦é‡‘æ•°æ® - ä½¿ç”¨XAUé»„é‡‘æœŸè´§æ•°æ®
            gold_data = ak.futures_foreign_hist(symbol="XAU")
            
            if gold_data.empty:
                print("âŒ æœªè·å–åˆ°ä¼¦æ•¦é‡‘æ•°æ®")
                return pd.DataFrame()
            
            print(f"ğŸ” åŸå§‹ä¼¦æ•¦é‡‘æ•°æ®åˆ—å: {gold_data.columns.tolist()}")
            print(f"ğŸ” åŸå§‹ä¼¦æ•¦é‡‘æ•°æ®å½¢çŠ¶: {gold_data.shape}")
            print(f"ğŸ” åŸå§‹ä¼¦æ•¦é‡‘æ•°æ®ç¤ºä¾‹:")
            print(gold_data.head(3))
            
            # æ•°æ®é¢„å¤„ç† - é€‚é…futures_foreign_histçš„æ•°æ®æ ¼å¼
            # è¯¥æ¥å£è¿”å›çš„æ˜¯æ—¥åº¦æ•°æ®ï¼Œéœ€è¦è½¬æ¢ä¸ºæ ‡å‡†OHLCVæ ¼å¼
            if 'æ—¥æœŸ' in gold_data.columns:
                # å°†æ—¥æœŸè½¬æ¢ä¸ºæ—¥æœŸç´¢å¼•
                gold_data['æ—¥æœŸ'] = pd.to_datetime(gold_data['æ—¥æœŸ'])
                gold_data = gold_data.set_index('æ—¥æœŸ')
            elif 'date' in gold_data.columns:
                gold_data['date'] = pd.to_datetime(gold_data['date'])
                gold_data = gold_data.set_index('date')
            else:
                # å¦‚æœæ²¡æœ‰æ—¥æœŸåˆ—ï¼Œä½¿ç”¨ç´¢å¼•
                gold_data.index = pd.to_datetime(gold_data.index)
            
            gold_data = gold_data.sort_index()
            
            # è·å–æœ€è¿‘Nä¸ªæœˆçš„æ•°æ®
            cutoff_date = datetime.now() - timedelta(days=months*30)
            gold_data = gold_data[gold_data.index >= cutoff_date]
            
            # æ£€æŸ¥å¹¶æ˜ å°„åˆ—ååˆ°æ ‡å‡†OHLCVæ ¼å¼
            column_mapping = {
                'open': 'å¼€ç›˜',
                'high': 'æœ€é«˜', 
                'low': 'æœ€ä½',
                'close': 'æ”¶ç›˜',
                'volume': 'æˆäº¤é‡'
            }
            
            # å¦‚æœåˆ—åæ˜¯è‹±æ–‡ï¼Œæ˜ å°„ä¸ºä¸­æ–‡
            for eng_col, chn_col in column_mapping.items():
                if eng_col in gold_data.columns and chn_col not in gold_data.columns:
                    gold_data[chn_col] = gold_data[eng_col]
                    print(f"âœ… æ˜ å°„åˆ— {eng_col} -> {chn_col}")
            
            # æ£€æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
            required_columns = ['å¼€ç›˜', 'æœ€é«˜', 'æœ€ä½', 'æ”¶ç›˜', 'æˆäº¤é‡']
            missing_columns = [col for col in required_columns if col not in gold_data.columns]
            
            if missing_columns:
                print(f"âš ï¸ ä¼¦æ•¦é‡‘æ•°æ®ç¼ºå°‘åˆ—: {missing_columns}")
                print(f"ğŸ” å¯ç”¨åˆ—: {gold_data.columns.tolist()}")
                
                # å¦‚æœç¼ºå°‘æˆäº¤é‡ï¼Œç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
                if 'æˆäº¤é‡' not in gold_data.columns:
                    import numpy as np
                    gold_data['æˆäº¤é‡'] = np.random.randint(1000, 10000, len(gold_data))
                    print(f"âœ… å·²ç”Ÿæˆæ¨¡æ‹Ÿæˆäº¤é‡æ•°æ®")
                
                # å¦‚æœç¼ºå°‘å…¶ä»–OHLCåˆ—ï¼Œä½¿ç”¨æ”¶ç›˜ä»·ç”Ÿæˆ
                for col in ['å¼€ç›˜', 'æœ€é«˜', 'æœ€ä½']:
                    if col not in gold_data.columns and 'æ”¶ç›˜' in gold_data.columns:
                        if col == 'å¼€ç›˜':
                            gold_data[col] = gold_data['æ”¶ç›˜'] * (0.98 + 0.04 * np.random.random(len(gold_data)))
                        elif col == 'æœ€é«˜':
                            gold_data[col] = gold_data['æ”¶ç›˜'] * (1 + 0.02 * np.random.random(len(gold_data)))
                        elif col == 'æœ€ä½':
                            gold_data[col] = gold_data['æ”¶ç›˜'] * (1 - 0.02 * np.random.random(len(gold_data)))
                        print(f"âœ… å·²ç”Ÿæˆæ¨¡æ‹Ÿ{col}æ•°æ®")
            
            print(f"âœ… ä¼¦æ•¦é‡‘æ•°æ®å¤„ç†å®Œæˆ")
            print(f"ğŸ“Š æœ€ç»ˆåˆ—å: {gold_data.columns.tolist()}")
            print(f"ğŸ“Š æ•°æ®ç¤ºä¾‹:")
            print(gold_data[['å¼€ç›˜', 'æœ€é«˜', 'æœ€ä½', 'æ”¶ç›˜', 'æˆäº¤é‡']].head(3))
            
            print(f"âœ… æˆåŠŸè·å–ä¼¦æ•¦é‡‘ {len(gold_data)} æ¡æ•°æ®")
            if not gold_data.empty:
                print(f"ğŸ“ˆ æ•°æ®æ—¶é—´èŒƒå›´: {gold_data.index.min()} åˆ° {gold_data.index.max()}")
                print(f"ğŸ“Š æœ€ç»ˆåˆ—å: {gold_data.columns.tolist()}")
            return gold_data
            
        except Exception as e:
            print(f"âŒ è·å–ä¼¦æ•¦é‡‘æ•°æ®å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            return pd.DataFrame()
    
    
    def get_stock_name(self, stock_code):
        """
        æ ¹æ®è‚¡ç¥¨ä»£ç è·å–è‚¡ç¥¨åç§°
        
        Args:
            stock_code (str): è‚¡ç¥¨ä»£ç 
            
        Returns:
            str: è‚¡ç¥¨åç§°
        """
        stock_names = {
            '002155': 'æ¹–å—é»„é‡‘',
            '600547': 'å±±ä¸œé»„é‡‘',
            '000975': 'é“¶æ³°é»„é‡‘',
            '600489': 'ä¸­é‡‘é»„é‡‘',
            '002237': 'æ’é‚¦è‚¡ä»½',
            '600988': 'èµ¤å³°é»„é‡‘'
        }
        return stock_names.get(stock_code, f'è‚¡ç¥¨{stock_code}')
    
    def preprocess_data(self, stock_data, gold_data):
        """
        æ•°æ®é¢„å¤„ç†å’Œæ ‡å‡†åŒ–
        
        Args:
            stock_data: è‚¡ç¥¨æ•°æ® (DataFrame)
            gold_data: é‡‘ä»·æ•°æ® (DataFrame)
            
        Returns:
            tuple: (å¤„ç†åçš„è‚¡ç¥¨æ•°æ®, å¤„ç†åçš„é‡‘ä»·æ•°æ®, æ˜¯å¦æœ‰æˆäº¤é‡æ•°æ®)
        """
        print("å¼€å§‹æ•°æ®é¢„å¤„ç†...")
        
        # æ£€æŸ¥æˆäº¤é‡æ•°æ®å¯ç”¨æ€§
        has_stock_volume = 'æˆäº¤é‡' in stock_data.columns and not stock_data['æˆäº¤é‡'].isna().all()
        has_gold_volume = 'æˆäº¤é‡' in gold_data.columns and not gold_data['æˆäº¤é‡'].isna().all()
        
        print(f"æˆäº¤é‡æ•°æ®çŠ¶æ€: è‚¡ç¥¨={has_stock_volume}, é‡‘ä»·={has_gold_volume}")
        
        # å¦‚æœæ²¡æœ‰æˆäº¤é‡æ•°æ®ï¼Œä¸æ·»åŠ é»˜è®¤å€¼
        if not has_stock_volume:
            print("è‚¡ç¥¨æ•°æ®æ— æˆäº¤é‡ï¼Œå°†è·³è¿‡æˆäº¤é‡ç›¸å…³è®¡ç®—")
        if not has_gold_volume:
            print("é‡‘ä»·æ•°æ®æ— æˆäº¤é‡ï¼Œå°†è·³è¿‡æˆäº¤é‡ç›¸å…³è®¡ç®—")
        
        # è®¡ç®—æ—¥æ¶¨è·Œå¹…
        stock_data['æ¶¨è·Œå¹…'] = stock_data['æ”¶ç›˜'].pct_change()
        gold_data['æ¶¨è·Œå¹…'] = gold_data['æ”¶ç›˜'].pct_change()
        
        # è®¡ç®—ç§»åŠ¨å¹³å‡çº¿
        for window in [5, 10, 20]:
            stock_data[f'MA{window}'] = stock_data['æ”¶ç›˜'].rolling(window=window).mean()
            gold_data[f'MA{window}'] = gold_data['æ”¶ç›˜'].rolling(window=window).mean()
        
        # è®¡ç®—æ³¢åŠ¨ç‡
        stock_data['æ³¢åŠ¨ç‡'] = stock_data['æ¶¨è·Œå¹…'].rolling(window=5).std()
        gold_data['æ³¢åŠ¨ç‡'] = gold_data['æ¶¨è·Œå¹…'].rolling(window=5).std()
        
        # åªåˆ é™¤å¿…è¦çš„NaNå€¼ï¼Œä¿ç•™æ›´å¤šæ•°æ®
        # åˆ é™¤å‰å‡ è¡Œçš„NaNï¼ˆç”±äºç§»åŠ¨å¹³å‡çº¿è®¡ç®—ï¼‰
        stock_data = stock_data.dropna(subset=['MA20'])  # åªåˆ é™¤MA20ä¸ºNaNçš„è¡Œ
        gold_data = gold_data.dropna(subset=['MA20'])
        
        # ç¡®ä¿ç´¢å¼•æ˜¯æ—¥æœŸç±»å‹
        if not isinstance(stock_data.index, pd.DatetimeIndex):
            try:
                stock_data.index = pd.to_datetime(stock_data.index)
            except:
                pass
        
        if not isinstance(gold_data.index, pd.DatetimeIndex):
            try:
                gold_data.index = pd.to_datetime(gold_data.index)
            except:
                pass
        
        print(f"æ•°æ®é¢„å¤„ç†å®Œæˆ")
        print(f"   è‚¡ç¥¨æ•°æ®: {len(stock_data)} æ¡è®°å½•")
        print(f"   é‡‘ä»·æ•°æ®: {len(gold_data)} æ¡è®°å½•")
        print(f"   è‚¡ç¥¨æ•°æ®ç´¢å¼•ç±»å‹: {type(stock_data.index)}")
        print(f"   é‡‘ä»·æ•°æ®ç´¢å¼•ç±»å‹: {type(gold_data.index)}")
        if len(stock_data) > 0:
            print(f"   è‚¡ç¥¨æ•°æ®ç´¢å¼•ç¤ºä¾‹: {stock_data.index[0]}")
        if len(gold_data) > 0:
            print(f"   é‡‘ä»·æ•°æ®ç´¢å¼•ç¤ºä¾‹: {gold_data.index[0]}")
        
        return stock_data, gold_data, (has_stock_volume, has_gold_volume)
    
    def calculate_correlation_similarity(self, stock_data, gold_data):
        """
        è®¡ç®—ä»·æ ¼å˜åŒ–ç›¸å…³æ€§ç›¸ä¼¼åº¦
        
        ç®—æ³•è¯´æ˜ï¼š
        1. è®¡ç®—ä¸¤æ¡Kçº¿çš„æ—¥æ¶¨è·Œå¹…
        2. è®¡ç®—çš®å°”é€Šç›¸å…³ç³»æ•°
        3. å°†ç›¸å…³ç³»æ•°(-1åˆ°1)è½¬æ¢ä¸ºç›¸ä¼¼åº¦åˆ†æ•°(0åˆ°100)
        
        Args:
            stock_data: è‚¡ç¥¨æ•°æ®
            gold_data: é‡‘ä»·æ•°æ®
            
        Returns:
            float: ç›¸å…³æ€§ç›¸ä¼¼åº¦åˆ†æ•° (0-100)
        """
        print("è®¡ç®—ä»·æ ¼å˜åŒ–ç›¸å…³æ€§...")
        
        # è·å–æ¶¨è·Œå¹…æ•°æ®
        stock_changes = stock_data['æ¶¨è·Œå¹…'].dropna()
        gold_changes = gold_data['æ¶¨è·Œå¹…'].dropna()
        
        # ç¡®ä¿æ•°æ®é•¿åº¦ä¸€è‡´
        min_length = min(len(stock_changes), len(gold_changes))
        if min_length < 2:
            return 0.0
            
        stock_changes = stock_changes.iloc[-min_length:]
        gold_changes = gold_changes.iloc[-min_length:]
        
        # è®¡ç®—çš®å°”é€Šç›¸å…³ç³»æ•°
        try:
            correlation, p_value = stats.pearsonr(stock_changes, gold_changes)
            
            # å°†ç›¸å…³ç³»æ•°è½¬æ¢ä¸ºç›¸ä¼¼åº¦åˆ†æ•°
            # ç›¸å…³ç³»æ•°èŒƒå›´: -1 åˆ° 1
            # ç›¸ä¼¼åº¦åˆ†æ•°èŒƒå›´: 0 åˆ° 100
            similarity_score = max(0, (correlation + 1) * 50)
            
            print(f"   ç›¸å…³ç³»æ•°: {correlation:.4f}")
            print(f"   ç›¸å…³æ€§ç›¸ä¼¼åº¦: {similarity_score:.2f}")
            
            return similarity_score
            
        except Exception as e:
            print(f"   ç›¸å…³æ€§è®¡ç®—å¤±è´¥: {e}")
            return 0.0
    
    def calculate_trend_similarity(self, stock_data, gold_data):
        """
        è®¡ç®—è¶‹åŠ¿æ–¹å‘ä¸€è‡´æ€§ç›¸ä¼¼åº¦
        
        ç®—æ³•è¯´æ˜ï¼š
        1. è®¡ç®—ç§»åŠ¨å¹³å‡çº¿çš„æ–œç‡
        2. æ¯”è¾ƒè¶‹åŠ¿æ–¹å‘çš„ä¸€è‡´æ€§
        3. è®¡ç®—è¶‹åŠ¿å¼ºåº¦çš„ç›¸ä¼¼åº¦
        
        Args:
            stock_data: è‚¡ç¥¨æ•°æ®
            gold_data: é‡‘ä»·æ•°æ®
            
        Returns:
            float: è¶‹åŠ¿ç›¸ä¼¼åº¦åˆ†æ•° (0-100)
        """
        print("è®¡ç®—è¶‹åŠ¿æ–¹å‘ä¸€è‡´æ€§...")
        
        try:
            # è®¡ç®—MA5å’ŒMA20çš„æ–œç‡
            stock_ma5_slope = self._calculate_slope(stock_data['MA5'].dropna())
            stock_ma20_slope = self._calculate_slope(stock_data['MA20'].dropna())
            gold_ma5_slope = self._calculate_slope(gold_data['MA5'].dropna())
            gold_ma20_slope = self._calculate_slope(gold_data['MA20'].dropna())
            
            # è®¡ç®—è¶‹åŠ¿æ–¹å‘ä¸€è‡´æ€§
            ma5_direction_similarity = self._direction_similarity(stock_ma5_slope, gold_ma5_slope)
            ma20_direction_similarity = self._direction_similarity(stock_ma20_slope, gold_ma20_slope)
            
            # è®¡ç®—è¶‹åŠ¿å¼ºåº¦ç›¸ä¼¼åº¦
            ma5_strength_similarity = self._strength_similarity(stock_ma5_slope, gold_ma5_slope)
            ma20_strength_similarity = self._strength_similarity(stock_ma20_slope, gold_ma20_slope)
            
            # ç»¼åˆè®¡ç®—è¶‹åŠ¿ç›¸ä¼¼åº¦
            trend_similarity = (ma5_direction_similarity * 0.6 + ma20_direction_similarity * 0.4) * 0.7 + \
                             (ma5_strength_similarity * 0.6 + ma20_strength_similarity * 0.4) * 0.3
            
            print(f"   MA5æ–¹å‘ç›¸ä¼¼åº¦: {ma5_direction_similarity:.2f}")
            print(f"   MA20æ–¹å‘ç›¸ä¼¼åº¦: {ma20_direction_similarity:.2f}")
            print(f"   è¶‹åŠ¿ç›¸ä¼¼åº¦: {trend_similarity:.2f}")
            
            return trend_similarity
            
        except Exception as e:
            print(f"   è¶‹åŠ¿è®¡ç®—å¤±è´¥: {e}")
            return 0.0
    
    def calculate_volatility_similarity(self, stock_data, gold_data):
        """
        è®¡ç®—æ³¢åŠ¨æ€§ç›¸ä¼¼åº¦
        
        ç®—æ³•è¯´æ˜ï¼š
        1. è®¡ç®—ä»·æ ¼æ³¢åŠ¨å¹…åº¦å’Œé¢‘ç‡
        2. æ¯”è¾ƒå˜å¼‚ç³»æ•°
        3. åˆ†ææ³¢åŠ¨æ¨¡å¼çš„ç›¸ä¼¼æ€§
        
        Args:
            stock_data: è‚¡ç¥¨æ•°æ®
            gold_data: é‡‘ä»·æ•°æ®
            
        Returns:
            float: æ³¢åŠ¨æ€§ç›¸ä¼¼åº¦åˆ†æ•° (0-100)
        """
        print("è®¡ç®—æ³¢åŠ¨æ€§ç›¸ä¼¼åº¦...")
        
        try:
            # è®¡ç®—å˜å¼‚ç³»æ•° (æ ‡å‡†å·®/å‡å€¼)
            stock_cv = stock_data['æ¶¨è·Œå¹…'].std() / abs(stock_data['æ¶¨è·Œå¹…'].mean())
            gold_cv = gold_data['æ¶¨è·Œå¹…'].std() / abs(gold_data['æ¶¨è·Œå¹…'].mean())
            
            # è®¡ç®—å˜å¼‚ç³»æ•°ç›¸ä¼¼åº¦
            cv_similarity = 100 - abs(stock_cv - gold_cv) / max(stock_cv, gold_cv) * 100
            cv_similarity = max(0, cv_similarity)
            
            # è®¡ç®—æ³¢åŠ¨ç‡ç›¸ä¼¼åº¦
            stock_volatility = stock_data['æ³¢åŠ¨ç‡'].mean()
            gold_volatility = gold_data['æ³¢åŠ¨ç‡'].mean()
            
            volatility_similarity = 100 - abs(stock_volatility - gold_volatility) / max(stock_volatility, gold_volatility) * 100
            volatility_similarity = max(0, volatility_similarity)
            
            # ç»¼åˆæ³¢åŠ¨æ€§ç›¸ä¼¼åº¦
            volatility_similarity = (cv_similarity * 0.6 + volatility_similarity * 0.4)
            
            print(f"   å˜å¼‚ç³»æ•°ç›¸ä¼¼åº¦: {cv_similarity:.2f}")
            print(f"   æ³¢åŠ¨ç‡ç›¸ä¼¼åº¦: {volatility_similarity:.2f}")
            print(f"   æ³¢åŠ¨æ€§ç›¸ä¼¼åº¦: {volatility_similarity:.2f}")
            
            return volatility_similarity
            
        except Exception as e:
            print(f"   æ³¢åŠ¨æ€§è®¡ç®—å¤±è´¥: {e}")
            return 0.0
    
    def calculate_pattern_similarity(self, stock_data, gold_data):
        """
        è®¡ç®—ä»·æ ¼æ¨¡å¼åŒ¹é…ç›¸ä¼¼åº¦
        
        ç®—æ³•è¯´æ˜ï¼š
        1. æ ‡å‡†åŒ–ä»·æ ¼æ•°æ®
        2. ä½¿ç”¨DTW(åŠ¨æ€æ—¶é—´è§„æ•´)ç®—æ³•
        3. è®¡ç®—ä»·æ ¼åºåˆ—çš„ç›¸ä¼¼åº¦
        
        Args:
            stock_data: è‚¡ç¥¨æ•°æ®
            gold_data: é‡‘ä»·æ•°æ®
            
        Returns:
            float: æ¨¡å¼ç›¸ä¼¼åº¦åˆ†æ•° (0-100)
        """
        print("è®¡ç®—ä»·æ ¼æ¨¡å¼åŒ¹é…...")
        
        try:
            # æ ‡å‡†åŒ–ä»·æ ¼æ•°æ®
            stock_prices = stock_data['æ”¶ç›˜'].values
            gold_prices = gold_data['æ”¶ç›˜'].values
            
            # æ ‡å‡†åŒ–åˆ°0-1èŒƒå›´
            stock_normalized = (stock_prices - stock_prices.min()) / (stock_prices.max() - stock_prices.min())
            gold_normalized = (gold_prices - gold_prices.min()) / (gold_prices.max() - gold_prices.min())
            
            # ç¡®ä¿é•¿åº¦ä¸€è‡´
            min_length = min(len(stock_normalized), len(gold_normalized))
            stock_normalized = stock_normalized[:min_length]
            gold_normalized = gold_normalized[:min_length]
            
            # è®¡ç®—DTWè·ç¦» - ä½¿ç”¨tslearnä¸“ä¸šåº“
            dtw_distance = dtw(stock_normalized, gold_normalized)
            
            # å°†DTWè·ç¦»è½¬æ¢ä¸ºç›¸ä¼¼åº¦åˆ†æ•°
            # DTWè·ç¦»è¶Šå°ï¼Œç›¸ä¼¼åº¦è¶Šé«˜
            max_distance = np.sqrt(2 * min_length)  # ç†è®ºæœ€å¤§è·ç¦»
            pattern_similarity = max(0, 100 - (dtw_distance / max_distance) * 100)
            
            print(f"   DTWè·ç¦»: {dtw_distance:.4f}")
            print(f"   æ¨¡å¼ç›¸ä¼¼åº¦: {pattern_similarity:.2f}")
            
            return pattern_similarity
            
        except Exception as e:
            print(f"   æ¨¡å¼è®¡ç®—å¤±è´¥: {e}")
            return 0.0
    
    def calculate_volume_similarity(self, stock_data, gold_data, has_volume_data):
        """
        è®¡ç®—æˆäº¤é‡ä¸ä»·æ ¼å…³ç³»ç›¸ä¼¼åº¦
        
        ç®—æ³•è¯´æ˜ï¼š
        1. åˆ†ææˆäº¤é‡ä¸ä»·æ ¼å˜åŒ–çš„å…³ç³»
        2. è®¡ç®—æˆäº¤é‡ä¸æ¶¨è·Œå¹…çš„ç›¸å…³æ€§
        3. æ¯”è¾ƒæˆäº¤é‡æ¨¡å¼
        
        Args:
            stock_data: è‚¡ç¥¨æ•°æ®
            gold_data: é‡‘ä»·æ•°æ®
            has_volume_data: (has_stock_volume, has_gold_volume) æˆäº¤é‡æ•°æ®å¯ç”¨æ€§
            
        Returns:
            float: æˆäº¤é‡ç›¸ä¼¼åº¦åˆ†æ•° (0-100)
        """
        has_stock_volume, has_gold_volume = has_volume_data
        
        # å¦‚æœä»»ä¸€æ•°æ®æºæ²¡æœ‰æˆäº¤é‡ï¼Œè¿”å›ä¸­æ€§åˆ†æ•°
        if not has_stock_volume or not has_gold_volume:
            print("æˆäº¤é‡æ•°æ®ä¸å®Œæ•´ï¼Œè·³è¿‡æˆäº¤é‡ç›¸ä¼¼åº¦è®¡ç®—")
            return 50.0  # è¿”å›ä¸­æ€§åˆ†æ•°ï¼Œä¸å½±å“æ€»ä½“è®¡ç®—
        
        print("è®¡ç®—æˆäº¤é‡å…³ç³»ç›¸ä¼¼åº¦...")
        
        try:
            # è®¡ç®—æˆäº¤é‡ä¸ä»·æ ¼å˜åŒ–çš„ç›¸å…³æ€§
            stock_volume_correlation = stock_data['æˆäº¤é‡'].corr(stock_data['æ¶¨è·Œå¹…'].abs())
            gold_volume_correlation = gold_data['æˆäº¤é‡'].corr(gold_data['æ¶¨è·Œå¹…'].abs())
            
            # è®¡ç®—ç›¸å…³æ€§ç›¸ä¼¼åº¦
            correlation_similarity = 100 - abs(stock_volume_correlation - gold_volume_correlation) * 100
            correlation_similarity = max(0, correlation_similarity)
            
            # è®¡ç®—æˆäº¤é‡å˜å¼‚ç³»æ•°ç›¸ä¼¼åº¦
            stock_volume_cv = stock_data['æˆäº¤é‡'].std() / stock_data['æˆäº¤é‡'].mean()
            gold_volume_cv = gold_data['æˆäº¤é‡'].std() / gold_data['æˆäº¤é‡'].mean()
            
            volume_cv_similarity = 100 - abs(stock_volume_cv - gold_volume_cv) / max(stock_volume_cv, gold_volume_cv) * 100
            volume_cv_similarity = max(0, volume_cv_similarity)
            
            # ç»¼åˆæˆäº¤é‡ç›¸ä¼¼åº¦
            volume_similarity = (correlation_similarity * 0.7 + volume_cv_similarity * 0.3)
            
            print(f"   æˆäº¤é‡ç›¸å…³æ€§ç›¸ä¼¼åº¦: {correlation_similarity:.2f}")
            print(f"   æˆäº¤é‡å˜å¼‚ç›¸ä¼¼åº¦: {volume_cv_similarity:.2f}")
            print(f"   æˆäº¤é‡ç›¸ä¼¼åº¦: {volume_similarity:.2f}")
            
            return volume_similarity
            
        except Exception as e:
            print(f"   æˆäº¤é‡è®¡ç®—å¤±è´¥: {e}")
            return 50.0  # è¿”å›ä¸­æ€§åˆ†æ•°
    
    def calculate_comprehensive_similarity(self, stock_data, gold_data):
        """
        è®¡ç®—ç»¼åˆç›¸ä¼¼åº¦åˆ†æ•°
        
        ç®—æ³•è¯´æ˜ï¼š
        1. è®¡ç®—å„ä¸ªç»´åº¦çš„ç›¸ä¼¼åº¦
        2. æ ¹æ®æƒé‡åŠ æƒè®¡ç®—
        3. è¿”å›æœ€ç»ˆç›¸ä¼¼åº¦åˆ†æ•°å’Œè¯¦ç»†åˆ†æ
        
        Args:
            stock_data: è‚¡ç¥¨æ•°æ®
            gold_data: é‡‘ä»·æ•°æ®
            
        Returns:
            dict: åŒ…å«ç»¼åˆç›¸ä¼¼åº¦å’Œè¯¦ç»†åˆ†æçš„å­—å…¸
        """
        print("å¼€å§‹ç»¼åˆç›¸ä¼¼åº¦åˆ†æ...")
        print("=" * 50)
        
        # æ•°æ®é¢„å¤„ç†
        stock_processed, gold_processed, has_volume_data = self.preprocess_data(stock_data, gold_data)
        
        # è®¡ç®—å„ä¸ªç»´åº¦çš„ç›¸ä¼¼åº¦
        similarity_scores = {}
        
        # 1. ä»·æ ¼å˜åŒ–ç›¸å…³æ€§
        similarity_scores['correlation'] = self.calculate_correlation_similarity(stock_processed, gold_processed)
        
        # 2. è¶‹åŠ¿æ–¹å‘ä¸€è‡´æ€§
        similarity_scores['trend'] = self.calculate_trend_similarity(stock_processed, gold_processed)
        
        # 3. æ³¢åŠ¨æ€§ç›¸ä¼¼åº¦
        similarity_scores['volatility'] = self.calculate_volatility_similarity(stock_processed, gold_processed)
        
        # 4. ä»·æ ¼æ¨¡å¼åŒ¹é…
        similarity_scores['pattern'] = self.calculate_pattern_similarity(stock_processed, gold_processed)
        
        # 5. æˆäº¤é‡å…³ç³»
        similarity_scores['volume'] = self.calculate_volume_similarity(stock_processed, gold_processed, has_volume_data)
        
        # è®¡ç®—åŠ æƒç»¼åˆç›¸ä¼¼åº¦
        comprehensive_score = 0
        for dimension, score in similarity_scores.items():
            comprehensive_score += score * self.weights[dimension]
        
        # è®¡ç®—æ¯æ—¥ç›¸ä¼¼åº¦æ—¶é—´åºåˆ—
        daily_similarity_data = self.calculate_daily_similarity(stock_data, gold_data)
        
        # ç”Ÿæˆåˆ†ææŠ¥å‘Š
        analysis_report = {
            'comprehensive_score': round(comprehensive_score, 2),
            'dimension_scores': similarity_scores,
            'weights': self.weights,
            'stock_data': stock_processed,
            'gold_data': gold_processed,
            'daily_similarity': daily_similarity_data,
            'analysis_summary': self._generate_analysis_summary(similarity_scores, comprehensive_score)
        }
        
        print("=" * 50)
        print("ç»¼åˆç›¸ä¼¼åº¦åˆ†æç»“æœ:")
        print(f"   ç»¼åˆç›¸ä¼¼åº¦åˆ†æ•°: {comprehensive_score:.2f}/100")
        print(f"   å„ç»´åº¦åˆ†æ•°: {similarity_scores}")
        print(f"   åˆ†ææ‘˜è¦: {analysis_report['analysis_summary']}")
        
        return analysis_report
    
    def calculate_daily_similarity(self, stock_data, gold_data, window_size=5):
        """
        è®¡ç®—æ¯æ—¥ç›¸ä¼¼åº¦æ—¶é—´åºåˆ—
        
        Args:
            stock_data: è‚¡ç¥¨æ•°æ®
            gold_data: é‡‘ä»·æ•°æ®
            window_size: æ»‘åŠ¨çª—å£å¤§å°
            
        Returns:
            dict: åŒ…å«æ¯æ—¥ç›¸ä¼¼åº¦æ•°æ®çš„å­—å…¸
        """
        print(f"è®¡ç®—æ¯æ—¥ç›¸ä¼¼åº¦ï¼Œçª—å£å¤§å°: {window_size}")
        
        # æ•°æ®é¢„å¤„ç†
        stock_processed, gold_processed, has_volume_data = self.preprocess_data(stock_data, gold_data)
        
        # ç¡®ä¿æ•°æ®é•¿åº¦ä¸€è‡´
        min_length = min(len(stock_processed), len(gold_processed))
        stock_processed = stock_processed.iloc[-min_length:]
        gold_processed = gold_processed.iloc[-min_length:]
        
        print(f"   å¤„ç†åçš„æ•°æ®é•¿åº¦: è‚¡ç¥¨={len(stock_processed)}, é‡‘ä»·={len(gold_processed)}")
        print(f"   è‚¡ç¥¨æ•°æ®ç´¢å¼•ç±»å‹: {type(stock_processed.index)}")
        print(f"   é‡‘ä»·æ•°æ®ç´¢å¼•ç±»å‹: {type(gold_processed.index)}")
        if len(stock_processed) > 0:
            print(f"   è‚¡ç¥¨æ•°æ®ç´¢å¼•ç¤ºä¾‹: {stock_processed.index[0]} -> {type(stock_processed.index[0])}")
        if len(gold_processed) > 0:
            print(f"   é‡‘ä»·æ•°æ®ç´¢å¼•ç¤ºä¾‹: {gold_processed.index[0]} -> {type(gold_processed.index[0])}")
        
        daily_similarities = []
        dates = []
        
        # ä½¿ç”¨æ»‘åŠ¨çª—å£è®¡ç®—æ¯æ—¥ç›¸ä¼¼åº¦
        for i in range(window_size, len(stock_processed)):
            # è·å–å½“å‰çª—å£çš„æ•°æ®
            stock_window = stock_processed.iloc[i-window_size:i+1]
            gold_window = gold_processed.iloc[i-window_size:i+1]
            
            # è®¡ç®—å½“å‰çª—å£çš„ç›¸ä¼¼åº¦
            try:
                # 1. ä»·æ ¼å˜åŒ–ç›¸å…³æ€§
                correlation_score = self.calculate_correlation_similarity(stock_window, gold_window)
                
                # 2. è¶‹åŠ¿ç›¸ä¼¼åº¦
                trend_score = self.calculate_trend_similarity(stock_window, gold_window)
                
                # 3. æ³¢åŠ¨æ€§ç›¸ä¼¼åº¦
                volatility_score = self.calculate_volatility_similarity(stock_window, gold_window)
                
                # 4. æ¨¡å¼ç›¸ä¼¼åº¦
                pattern_score = self.calculate_pattern_similarity(stock_window, gold_window)
                
                # 5. æˆäº¤é‡ç›¸ä¼¼åº¦
                volume_score = self.calculate_volume_similarity(stock_window, gold_window, has_volume_data)
                
                # è®¡ç®—åŠ æƒç»¼åˆç›¸ä¼¼åº¦
                daily_score = (
                    correlation_score * self.weights['correlation'] +
                    trend_score * self.weights['trend'] +
                    volatility_score * self.weights['volatility'] +
                    pattern_score * self.weights['pattern'] +
                    volume_score * self.weights['volume']
                )
                
                daily_similarities.append(round(daily_score, 2))
                # ç¡®ä¿æ—¥æœŸæ ¼å¼æ­£ç¡®
                if hasattr(stock_processed.index[i], 'strftime'):
                    dates.append(stock_processed.index[i].strftime('%Y-%m-%d'))
                else:
                    dates.append(str(stock_processed.index[i]))
                
            except Exception as e:
                print(f"   ç¬¬{i}å¤©ç›¸ä¼¼åº¦è®¡ç®—å¤±è´¥: {e}")
                daily_similarities.append(0.0)
                # ç¡®ä¿æ—¥æœŸæ ¼å¼æ­£ç¡®
                if hasattr(stock_processed.index[i], 'strftime'):
                    dates.append(stock_processed.index[i].strftime('%Y-%m-%d'))
                else:
                    dates.append(str(stock_processed.index[i]))
        
        print(f"æ¯æ—¥ç›¸ä¼¼åº¦è®¡ç®—å®Œæˆï¼Œå…±{len(daily_similarities)}ä¸ªæ•°æ®ç‚¹")
        if len(daily_similarities) > 0:
            print(f"   å¹³å‡ç›¸ä¼¼åº¦: {np.mean(daily_similarities):.2f}")
            print(f"   æœ€é«˜ç›¸ä¼¼åº¦: {np.max(daily_similarities):.2f}")
            print(f"   æœ€ä½ç›¸ä¼¼åº¦: {np.min(daily_similarities):.2f}")
        else:
            print("   æ²¡æœ‰è®¡ç®—åˆ°ç›¸ä¼¼åº¦æ•°æ®")
        
        if len(daily_similarities) > 0:
            return {
                'dates': dates,
                'similarities': daily_similarities,
                'mean_similarity': round(np.mean(daily_similarities), 2),
                'max_similarity': round(np.max(daily_similarities), 2),
                'min_similarity': round(np.min(daily_similarities), 2),
                'std_similarity': round(np.std(daily_similarities), 2)
            }
        else:
            return {
                'dates': [],
                'similarities': [],
                'mean_similarity': 0,
                'max_similarity': 0,
                'min_similarity': 0,
                'std_similarity': 0
            }
    
    def _calculate_slope(self, data):
        """è®¡ç®—æ•°æ®åºåˆ—çš„æ–œç‡"""
        if len(data) < 2:
            return 0
        x = np.arange(len(data))
        y = data.values
        slope, _ = np.polyfit(x, y, 1)
        return slope
    
    def _direction_similarity(self, slope1, slope2):
        """è®¡ç®—æ–œç‡æ–¹å‘ç›¸ä¼¼åº¦"""
        if slope1 * slope2 > 0:  # åŒæ–¹å‘
            return 100
        elif slope1 == 0 and slope2 == 0:  # éƒ½æ˜¯æ°´å¹³
            return 100
        else:  # åæ–¹å‘
            return 0
    
    def _strength_similarity(self, slope1, slope2):
        """è®¡ç®—æ–œç‡å¼ºåº¦ç›¸ä¼¼åº¦"""
        if slope1 == 0 and slope2 == 0:
            return 100
        
        ratio = min(abs(slope1), abs(slope2)) / max(abs(slope1), abs(slope2))
        return ratio * 100
    
    
    def _generate_analysis_summary(self, scores, comprehensive_score):
        """ç”Ÿæˆåˆ†ææ‘˜è¦"""
        if comprehensive_score >= 80:
            return "é«˜åº¦ç›¸ä¼¼ - ä¸¤æ¡Kçº¿èµ°åŠ¿é«˜åº¦ä¸€è‡´"
        elif comprehensive_score >= 60:
            return "ä¸­åº¦ç›¸ä¼¼ - ä¸¤æ¡Kçº¿èµ°åŠ¿æœ‰ä¸€å®šç›¸ä¼¼æ€§"
        elif comprehensive_score >= 40:
            return "ä½åº¦ç›¸ä¼¼ - ä¸¤æ¡Kçº¿èµ°åŠ¿ç›¸ä¼¼æ€§è¾ƒä½"
        else:
            return "å‡ ä¹ä¸ç›¸ä¼¼ - ä¸¤æ¡Kçº¿èµ°åŠ¿å·®å¼‚å¾ˆå¤§"


# æµ‹è¯•å‡½æ•°
def test_similarity_analyzer():
    """æµ‹è¯•ç›¸ä¼¼åº¦åˆ†æå™¨"""
    print("ğŸ§ª å¼€å§‹æµ‹è¯•ç›¸ä¼¼åº¦åˆ†æå™¨...")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    dates = pd.date_range('2024-01-01', periods=30, freq='D')
    
    # æ¨¡æ‹Ÿè‚¡ç¥¨æ•°æ®
    stock_data = pd.DataFrame({
        'æ—¥æœŸ': dates,
        'å¼€ç›˜': np.random.uniform(10, 15, 30),
        'æ”¶ç›˜': np.random.uniform(10, 15, 30),
        'æœ€é«˜': np.random.uniform(12, 18, 30),
        'æœ€ä½': np.random.uniform(8, 12, 30),
        'æˆäº¤é‡': np.random.uniform(1000000, 5000000, 30)
    })
    stock_data.set_index('æ—¥æœŸ', inplace=True)
    
    # æ¨¡æ‹Ÿé‡‘ä»·æ•°æ®
    gold_data = pd.DataFrame({
        'æ—¥æœŸ': dates,
        'å¼€ç›˜': np.random.uniform(2000, 2100, 30),
        'æ”¶ç›˜': np.random.uniform(2000, 2100, 30),
        'æœ€é«˜': np.random.uniform(2050, 2150, 30),
        'æœ€ä½': np.random.uniform(1950, 2050, 30),
        'æˆäº¤é‡': np.random.uniform(1000, 5000, 30)
    })
    gold_data.set_index('æ—¥æœŸ', inplace=True)
    
    # åˆ›å»ºåˆ†æå™¨å¹¶æµ‹è¯•
    analyzer = SimilarityAnalyzer()
    result = analyzer.calculate_comprehensive_similarity(stock_data, gold_data)
    
    print("æµ‹è¯•å®Œæˆ!")
    return result

